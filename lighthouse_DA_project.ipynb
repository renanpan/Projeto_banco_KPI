{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Desafio Análise de Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Nem todos os envolvidos estão convictos com a ideia de uma frente de BIs no BanVic. Como podemos convencer Camila Diniz, diretora comercial,  que as nossas soluções serão úteis para a empresa? Com base na análise exploratória realizada nos dados apresentados, quais perguntas de negócio podemos responder para mostrar o valor que dados possuem para a empresa? Pergunta de nível teórico. O seu projeto final não necessariamente precisa trazer os mesmos ou todos os indicadores citados nessa entrega.\n",
    "\n",
    "\n",
    "2. Quais serão os indicadores ou visualizações utilizadas para responder às perguntas de negócio citadas anteriormente? Pergunta de nível teórico. O seu projeto final não necessariamente precisa trazer os mesmos ou todos os indicadores citados nessa entrega.\n",
    "\n",
    "\n",
    "3. Apresentar pelo menos duas análises de negócio para cada uma das categorias. Pergunta de nível teórico. O seu projeto final não necessariamente precisa ter todas análises citadas nessa entrega: \n",
    "\n",
    "\n",
    "        Uma análise descritiva;\n",
    "        Uma análise diagnóstica;\n",
    "        Uma análise prescritiva;\n",
    "        Uma análise preditiva.\n",
    "\n",
    "\n",
    "4. Um relatório em PDF com suas análises, justificativas e raciocínio contendo os seguintes pontos:\n",
    "\n",
    "        As respostas do item 1, 2 e 3.\n",
    "        Um tópico descrevendo brevemente quais os processos de transformação e tratamento de dados foram aplicados por você.\n",
    "        Um dashboard dos principais KPIs de negócio do BanVic permitindo um detalhamento por data, por agência e por clientes.\n",
    "        Apresentar as análises que foram necessárias para o entendimento do negócio e que podem ser úteis no suporte para a tomada de decisão.\n",
    "        E finalmente, com base nas suas análises, uma conclusão com recomendações/sugestões de negócio e encaminhamentos para a CEO do BanVic.\n",
    "        Apresentar e justificar as ferramentas adotadas para a elaboração das análises.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1° importar as bibliotecas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importar bibliotecas\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2° Importar e criar os dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#criar as tabelas para trabalhar\n",
    "\n",
    "agencias = pd.read_csv(\"data/agencias.csv\")\n",
    "clientes = pd.read_csv('data/clientes.csv')\n",
    "colaborador_agencia = pd.read_csv('data/colaborador_agencia.csv')\n",
    "colaboradores = pd.read_csv('data/colaboradores.csv')\n",
    "contas = pd.read_csv('data/contas.csv')\n",
    "propostas_credito = pd.read_csv('data/propostas_credito.csv')\n",
    "transacoes = pd.read_csv('data/transacoes.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3° Analisar cada um dos dataframes e transformar os dados conforme necessário"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 DataFrame 'agencias'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10 entries, 0 to 9\n",
      "Data columns (total 7 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   cod_agencia    10 non-null     int64 \n",
      " 1   nome           10 non-null     object\n",
      " 2   endereco       10 non-null     object\n",
      " 3   cidade         10 non-null     object\n",
      " 4   uf             10 non-null     object\n",
      " 5   data_abertura  10 non-null     object\n",
      " 6   tipo_agencia   10 non-null     object\n",
      "dtypes: int64(1), object(6)\n",
      "memory usage: 692.0+ bytes\n",
      "\n",
      "   cod_agencia              nome  \\\n",
      "0            7   Agência Digital   \n",
      "1            1    Agência Matriz   \n",
      "2            2   Agência Tatuapé   \n",
      "3            3  Agência Campinas   \n",
      "4            4    Agência Osasco   \n",
      "\n",
      "                                            endereco     cidade  uf  \\\n",
      "0  Av. Paulista, 1436 - Cerqueira César, São Paul...  São Paulo  SP   \n",
      "1  Av. Paulista, 1436 - Cerqueira César, São Paul...  São Paulo  SP   \n",
      "2  Praça Sílvio Romero, 158 - Tatuapé, São Paulo ...  São Paulo  SP   \n",
      "3  Av. Francisco Glicério, 895 - Vila Lidia, Camp...   Campinas  SP   \n",
      "4  Av. Antônio Carlos Costa, 1000 - Bela Vista, O...     Osasco  SP   \n",
      "\n",
      "  data_abertura tipo_agencia  \n",
      "0    2015-08-01      Digital  \n",
      "1    2010-01-01       Física  \n",
      "2    2010-06-14       Física  \n",
      "3    2012-03-04       Física  \n",
      "4    2013-11-06       Física  \n"
     ]
    }
   ],
   "source": [
    "agencias.info()\n",
    "\n",
    "print()\n",
    "print(agencias.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Os dados dos cabeçalhos se encontram de padronizados em letra minuscula e snake case. \n",
    "    O arquivo possui dez entradas e nenhuma das células apresenta valores nulos.\n",
    "    É necessário alterar o tipo de dados para datetime na coluna data_abertura."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10 entries, 0 to 9\n",
      "Data columns (total 7 columns):\n",
      " #   Column         Non-Null Count  Dtype         \n",
      "---  ------         --------------  -----         \n",
      " 0   cod_agencia    10 non-null     int64         \n",
      " 1   nome           10 non-null     object        \n",
      " 2   endereco       10 non-null     object        \n",
      " 3   cidade         10 non-null     object        \n",
      " 4   uf             10 non-null     object        \n",
      " 5   data_abertura  10 non-null     datetime64[ns]\n",
      " 6   tipo_agencia   10 non-null     object        \n",
      "dtypes: datetime64[ns](1), int64(1), object(5)\n",
      "memory usage: 692.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "#transformando os dados para datetime\n",
    "agencias['data_abertura'] = pd.to_datetime(agencias['data_abertura'])\n",
    "\n",
    "#conferindo\n",
    "agencias.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 DataFrame 'clientes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 998 entries, 0 to 997\n",
      "Data columns (total 10 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   cod_cliente      998 non-null    int64 \n",
      " 1   primeiro_nome    998 non-null    object\n",
      " 2   ultimo_nome      998 non-null    object\n",
      " 3   email            998 non-null    object\n",
      " 4   tipo_cliente     998 non-null    object\n",
      " 5   data_inclusao    998 non-null    object\n",
      " 6   cpfcnpj          998 non-null    object\n",
      " 7   data_nascimento  998 non-null    object\n",
      " 8   endereco         998 non-null    object\n",
      " 9   cep              998 non-null    object\n",
      "dtypes: int64(1), object(9)\n",
      "memory usage: 78.1+ KB\n",
      "\n",
      "   cod_cliente primeiro_nome ultimo_nome                         email  \\\n",
      "0           28       Sabrina        Dias  moreiraemanuelly@example.org   \n",
      "1          674   Luiz Felipe        Dias     pedroferreira@example.org   \n",
      "2          693         Renan        Dias            ogomes@example.net   \n",
      "3          743         Clara        Dias     rafaelcorreia@example.org   \n",
      "4          769         André        Dias          danilo33@example.org   \n",
      "\n",
      "  tipo_cliente            data_inclusao         cpfcnpj data_nascimento  \\\n",
      "0           PF  2017-04-03 16:11:00 UTC  357.081.496-39      2006-08-11   \n",
      "1           PF  2021-02-10 13:27:00 UTC  085.196.374-93      1995-10-11   \n",
      "2           PF  2020-01-21 13:12:00 UTC  783.416.059-10      1948-11-19   \n",
      "3           PF  2019-05-06 11:39:00 UTC  589.237.610-95      1978-01-27   \n",
      "4           PF  2017-01-07 14:53:00 UTC  459.608.721-02      1990-08-25   \n",
      "\n",
      "                                            endereco        cep  \n",
      "0  Praia de Duarte Vila Piratininga 81327-166 Fer...  95140-704  \n",
      "1  Avenida da Rosa, 654 João Paulo Ii 20295449 Nu...  76516-765  \n",
      "2  Jardim de Rodrigues Ipiranga 14161-477 Duarte ...   51779625  \n",
      "3  Colônia Thomas Silva, 9 Tupi B 15771-946 Ferna...   19615792  \n",
      "4     Rua Correia, 889 Diamante 59123250 Aragão / RS   01672838  \n"
     ]
    }
   ],
   "source": [
    "clientes.info()\n",
    "print()\n",
    "print(clientes.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    É necessário transformar as colunas de data (data_inclusao e data_nascimento) para corresponderem ao formato datetime;\n",
    "    É necessário padronizar o formato CEP para ter o traço.\n",
    "    Não há células com valores nulos dentro do DataFrame 'clientes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#arrumar os dados correspondentes para datetime\n",
    "\n",
    "clientes['data_inclusao'] = pd.to_datetime(clientes['data_inclusao'], format=\"%Y-%m-%d %H:%M:%S\")\n",
    "clientes['data_nascimento'] = pd.to_datetime(clientes['data_nascimento'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criar uma função para arrumar os dados de CEP\n",
    "\n",
    "def formatar_cep(cep):\n",
    "    if '-' not in cep:\n",
    "        return f\"{cep[:5]}-{cep[5:]}\"\n",
    "    else:\n",
    "        return cep\n",
    "\n",
    "# Aplicar a função à coluna desejada\n",
    "clientes['cep'] = clientes['cep'].apply(formatar_cep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "793    50987-872\n",
      "843    38041-732\n",
      "974    88118-294\n",
      "828    80604-493\n",
      "321    78151-537\n",
      "18     37988-526\n",
      "238    00147-561\n",
      "93     68301-753\n",
      "170    44030-253\n",
      "16     77226-042\n",
      "Name: cep, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#conferir se realizou a troca\n",
    "print(clientes['cep'].sample(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 DataFrame 'colaborador_agencia'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 2 columns):\n",
      " #   Column           Non-Null Count  Dtype\n",
      "---  ------           --------------  -----\n",
      " 0   cod_colaborador  100 non-null    int64\n",
      " 1   cod_agencia      100 non-null    int64\n",
      "dtypes: int64(2)\n",
      "memory usage: 1.7 KB\n"
     ]
    }
   ],
   "source": [
    "#conferir os dados\n",
    "colaborador_agencia.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    O DataFrame colaborador_agencia não possui valores nulos nas células, nem valores que precisam ter seus tipos alterados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 DataFrame 'colaboradores'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 8 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   cod_colaborador  100 non-null    int64 \n",
      " 1   primeiro_nome    100 non-null    object\n",
      " 2   ultimo_nome      100 non-null    object\n",
      " 3   email            100 non-null    object\n",
      " 4   cpf              100 non-null    object\n",
      " 5   data_nascimento  100 non-null    object\n",
      " 6   endereco         100 non-null    object\n",
      " 7   cep              100 non-null    object\n",
      "dtypes: int64(1), object(7)\n",
      "memory usage: 6.4+ KB\n"
     ]
    }
   ],
   "source": [
    "#Conferindo os dados do DataFrame 'colaboradores'\n",
    "\n",
    "colaboradores.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69    1991-10-10\n",
      "96    1992-01-12\n",
      "4     1996-03-01\n",
      "23    1974-06-03\n",
      "41    1981-05-08\n",
      "Name: data_nascimento, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#amostrar o formato de data de nascimento dos colaboradores \n",
    "print(colaboradores['data_nascimento'].sample(5))\n",
    "\n",
    "#converter o tipo de dados para datetime\n",
    "\n",
    "colaboradores['data_nascimento'] = pd.to_datetime(colaboradores['data_nascimento'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    O DataFrame 'colaboradores' não possui valores nulos e foi necessário alterar o tipo de dados do campo data_nascimento para datetime."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 DataFrame 'contas'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 999 entries, 0 to 998\n",
      "Data columns (total 9 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   num_conta               999 non-null    int64  \n",
      " 1   cod_cliente             999 non-null    int64  \n",
      " 2   cod_agencia             999 non-null    int64  \n",
      " 3   cod_colaborador         999 non-null    int64  \n",
      " 4   tipo_conta              999 non-null    object \n",
      " 5   data_abertura           999 non-null    object \n",
      " 6   saldo_total             999 non-null    float64\n",
      " 7   saldo_disponivel        999 non-null    float64\n",
      " 8   data_ultimo_lancamento  999 non-null    object \n",
      "dtypes: float64(2), int64(4), object(3)\n",
      "memory usage: 70.4+ KB\n"
     ]
    }
   ],
   "source": [
    "#entender os dados do DataFrame 'contas'\n",
    "\n",
    "contas.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               data_abertura          data_ultimo_lancamento\n",
      "576  2020-09-03 14:33:00 UTC  2022-12-29 23:59:59.616802 UTC\n",
      "883  2017-04-04 14:29:00 UTC  2022-12-29 23:59:59.589471 UTC\n",
      "500  2021-06-24 15:39:00 UTC  2022-12-29 23:59:59.045471 UTC\n",
      "859  2016-08-16 13:16:00 UTC         2019-12-20 19:18:15 UTC\n",
      "536  2020-10-02 10:21:00 UTC  2022-12-30 00:00:00.848782 UTC\n"
     ]
    }
   ],
   "source": [
    "print(contas[['data_abertura','data_ultimo_lancamento']].sample(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "time data \"2022-12-30 00:00:00.67516 UTC\" doesn't match format \"%Y-%m-%d %H:%M:%S %Z\", at position 6. You might want to try:\n    - passing `format` if your strings have a consistent format;\n    - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n    - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[66], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#transformar as colunas de data para o formato datetime\u001b[39;00m\n\u001b[0;32m      2\u001b[0m contas[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata_abertura\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(contas[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata_abertura\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m----> 4\u001b[0m contas[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata_ultimo_lancamento\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_datetime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontas\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata_ultimo_lancamento\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\renan\\Python\\Lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1112\u001b[0m, in \u001b[0;36mto_datetime\u001b[1;34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[0m\n\u001b[0;32m   1110\u001b[0m         result \u001b[38;5;241m=\u001b[39m arg\u001b[38;5;241m.\u001b[39mmap(cache_array)\n\u001b[0;32m   1111\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1112\u001b[0m         values \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_listlike\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1113\u001b[0m         result \u001b[38;5;241m=\u001b[39m arg\u001b[38;5;241m.\u001b[39m_constructor(values, index\u001b[38;5;241m=\u001b[39marg\u001b[38;5;241m.\u001b[39mindex, name\u001b[38;5;241m=\u001b[39marg\u001b[38;5;241m.\u001b[39mname)\n\u001b[0;32m   1114\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arg, (ABCDataFrame, abc\u001b[38;5;241m.\u001b[39mMutableMapping)):\n",
      "File \u001b[1;32mc:\\Users\\renan\\Python\\Lib\\site-packages\\pandas\\core\\tools\\datetimes.py:488\u001b[0m, in \u001b[0;36m_convert_listlike_datetimes\u001b[1;34m(arg, format, name, utc, unit, errors, dayfirst, yearfirst, exact)\u001b[0m\n\u001b[0;32m    486\u001b[0m \u001b[38;5;66;03m# `format` could be inferred, or user didn't ask for mixed-format parsing.\u001b[39;00m\n\u001b[0;32m    487\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmixed\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 488\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_array_strptime_with_fallback\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mutc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexact\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    490\u001b[0m result, tz_parsed \u001b[38;5;241m=\u001b[39m objects_to_datetime64ns(\n\u001b[0;32m    491\u001b[0m     arg,\n\u001b[0;32m    492\u001b[0m     dayfirst\u001b[38;5;241m=\u001b[39mdayfirst,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    496\u001b[0m     allow_object\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    497\u001b[0m )\n\u001b[0;32m    499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tz_parsed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    500\u001b[0m     \u001b[38;5;66;03m# We can take a shortcut since the datetime64 numpy array\u001b[39;00m\n\u001b[0;32m    501\u001b[0m     \u001b[38;5;66;03m# is in UTC\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\renan\\Python\\Lib\\site-packages\\pandas\\core\\tools\\datetimes.py:519\u001b[0m, in \u001b[0;36m_array_strptime_with_fallback\u001b[1;34m(arg, name, utc, fmt, exact, errors)\u001b[0m\n\u001b[0;32m    508\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_array_strptime_with_fallback\u001b[39m(\n\u001b[0;32m    509\u001b[0m     arg,\n\u001b[0;32m    510\u001b[0m     name,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    514\u001b[0m     errors: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m    515\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Index:\n\u001b[0;32m    516\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    517\u001b[0m \u001b[38;5;124;03m    Call array_strptime, with fallback behavior depending on 'errors'.\u001b[39;00m\n\u001b[0;32m    518\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 519\u001b[0m     result, timezones \u001b[38;5;241m=\u001b[39m \u001b[43marray_strptime\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfmt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexact\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexact\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mutc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mutc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    520\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(tz \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m tz \u001b[38;5;129;01min\u001b[39;00m timezones):\n\u001b[0;32m    521\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _return_parsed_timezone_results(result, timezones, utc, name)\n",
      "File \u001b[1;32mstrptime.pyx:534\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.strptime.array_strptime\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mstrptime.pyx:355\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.strptime.array_strptime\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: time data \"2022-12-30 00:00:00.67516 UTC\" doesn't match format \"%Y-%m-%d %H:%M:%S %Z\", at position 6. You might want to try:\n    - passing `format` if your strings have a consistent format;\n    - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n    - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this."
     ]
    }
   ],
   "source": [
    "#transformar as colunas de data para o formato datetime\n",
    "contas['data_abertura'] = pd.to_datetime(contas['data_abertura'])\n",
    "\n",
    "contas['data_ultimo_lancamento'] = pd.to_datetime(contas['data_ultimo_lancamento'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "608   2019-11-14 11:15:00+00:00\n",
      "206   2012-02-20 13:42:00+00:00\n",
      "607   2015-09-21 11:35:00+00:00\n",
      "52    2020-02-27 12:50:00+00:00\n",
      "544   2018-08-26 12:33:00+00:00\n",
      "Name: data_abertura, dtype: datetime64[ns, UTC]\n"
     ]
    }
   ],
   "source": [
    "print(contas['data_abertura'].sample(5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
